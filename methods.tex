\chapter{Methods and Implementations}

\section{DeepSIM}
\label{sec:DeepSIM}

3D structured illumination microscopy (3D-SIM) is a super-resolution microscopy technique which is well suited to imaging live biological samples due to the relatively few images required to reconstruct a super-resolution image. However, to date this application has not been exploited. This is for two principle reasons. Firstly, live biological samples have to be suspended in some form of media to sustain them. This required an upright microscopy configuration and all available SIM systems to date have an inverted configuration. Secondly, imaging a depths $>20\mu m$ remains a challenge for traditional 3D-SIM methods due to limited background rejection and optical aberrations degrading the stripe contrast necessary for successful SIM imaging.\cite{wu2018faster} Therefore most 3D-SIM imaging has been limited to thin specimens. DeepSIM is a bespoke microscope designed to address these issues, being an open and flexible upright microscope platform optimised for rapid 3D SIM image stacks deep in large samples by implementing adaptive optics. 

\subsection{DeepSIM Optical Set-up}
\label{subsec:DeepSIM_optics}

Figure~\ref{fig:DeepSIM_complete_beam_paths} shows the complete optical schematic of the DeepSIM microscope. There are multiple possible beam paths which can be altered by raising/lowering certain optics and/or pairs of mirrors. The solid green path denotes the primary 3D-SIM excitation path. The laser beams are combined at a single exit port, magnified and then reflected onto the spatial light modulator (SLM). The SLM acts as a diffraction grating imposing the structure to the illumination pattern required for SIM imaging. The beam is then demagnified and reimaged onto the deformable mirror. The beam is then demagnified further and directed to the $60\times$ water dipping objective. The emission beam path follows the same path in reverse up until the deformable mirror. At this point the emission beam path is redirected by a dichroic mirror (Chroma Technology ZT405/488/561/640rpc), magnified and then reimaged onto the Andor iXon EMCCD cameras. There is a secondary dichroic (Chroma Technology ZT561rdc-xr) which separates the "red" colour channel (562nm-800nm) from the "green" colour channel (390nm-562nm). 
	
\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth]{images/DeepSIM_complete_beam_paths.jpg}
	\caption{Complete beam path layout for DeepSIM. DeepSIM has multiple paths that can changed by flipping the numbered pairs/individual mirrors. The green paths denotes the exitation beam paths. The solid green path shows the structured illumination (SI) beam path. The dashed green path shows the widefield beam path. This is changed to the interference beam path but flipping up the lens and pellicle pair. The dot-dashed green path shows the excitation path which bypasses the deformable mirror. The dot-dot-dashed green path shows the excitation path going through the $10\times$ air objective. The orange path denotes the emission beam path.}
	\label{fig:DeepSIM_complete_beam_paths}
\end{figure}
	
Raising the \circled{1} pair of flip mirrors bypasses the SLM and changes the excitation beam path to a widefield configuration. Raising the \circled{2} pair of flip mirrors bypasses the DM. This is a useful configuration when the DM has not yet been calibrated since the neutral position of the DM actuators have a worse flatness profile than that of a plane mirror. Without calibration, the DM surface cannot be flattened and may contribute to the aberrations present in the imaging system. Raising the \circled{3} flip mirror directs the exitation beam path through the $10 \times$ air objective. This beam path is used for field of view (FOV) mapping.

Raising both the \circled{1} pair of flip mirrors and the \circled{4} flip mounted pellicle beamsplitter and lens changes both the excitation and emission beam paths to create an interferometer. Half of the excitation beam is picked off by the 50:50 beamsplitter and directed straight into the Ximea XiQ camera. This is the interferometer reference arm. The sample beam arm proceeds through the regular excitation beam path. Placing a mirror in the focal plane of the $60\times$ objective reflects the beam arm through the emission beam path until it is reflected by the pellicle into the Ximea XiQ camera. This interferogram can interrogated to yeild an image of the phase wavefront. Since the DM is in the sample arm, varying the shape of the DM surface will change the shape of the phase wavefront. Measuring how the movement of the DM's actuators influences the shape of the phase wavefront allows the DM to be calibrated. 

\subsection{Optical Alignment}
\label{subsec:alignment}
	
\begin{itemize}
	\item Here's an opportunity to talk about BeamDelta and the need to minimise optical misalignment as DMs (and  AO components in general) cannot offer infinite correction so you still want a well algined system you do minor corrections than a poorly aligned system that you can't fully correct.
\end{itemize}

\subsection{\textit{Microscope}}
\label{subsec:microscope}
	
\begin{itemize}
	\item Talk about the need for hardware control in bespoke microscope systems and for precise, coordinated timing control.
\end{itemize}

\subsection{\textit{Cockpit}}
\label{subsec:cockpit}

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.575\textwidth}
		\centering
		\includegraphics[width=\linewidth]{images/DeepSIM_control_software_main_window.png}
		\caption{}
		\label{fig:DeepSIM_control_software_main_window}
	\end{subfigure}
	\begin{subfigure}{0.365\textwidth}
		\centering
		\includegraphics[width=\linewidth]{images/DeepSIM_control_software_camera.png}
		\caption{}
		\label{fig:DeepSIM_control_software_camera}
	\end{subfigure}
		
	\begin{subfigure}{0.51\textwidth}
		\centering
		\includegraphics[width=\linewidth]{images/DeepSIM_control_software_stage_control.png}
		\caption{}
		\label{fig:DeepSIM_control_software_stage_control}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\linewidth]{images/DeepSIM_control_software_mosaic.png}
		\caption{}
		\label{fig:DeepSIM_control_software_mosaic}
	\end{subfigure}
	\caption{Cockpit UI for controlling DeepSIM (a) Cockpit main window. Contains buttons to enable all the hardware, set laser powers and change beam paths (b) Camera view window. Shows the most recent readout from all the enabled cameras (c) Stage control window. Allows the user to control the position of the XY piezo-stage, coarse mechanical Z stage and fine Z piezo-stage (d) Mosaic window. Used by the user to scan the field of view for structures of interest and mark them.}
	\label{fig:Cockpit_UI}
\end{figure}
	
\begin{itemize}
	\item Here need to talk about having an accessible interface for biologist to use.
	\item Mention peculiarities with DeepSIM (i.e. no eye pieces) and call back to the previous inaccessibly of AO to biologists due to complex interfaces.
\end{itemize}

\section{Adaptive Optics Control Software}
\label{sec:AOtools}

Implementing adaptive optics (AO) in microscopy has already been shown to be highly effective at removing optical aberrations and yielding significantly improvements to image quality.\cite{booth2014adaptive,girkin2009adaptive} However, AO technology has not been widely adopted due to a number of barriers. Firstly, it is not trivial to set-up an AO element such as the deformable mirror (DM) present in the DeepSIM optical path. The DM must be calibrated to meaningfully recreate and correct aberrations, but performing this step is not something non-specialist user may know how to do or how to assess if the process has been successful.vSecondly, measuring the wavefront deformations (and therefore the aberrations) present in a sample is complicated. While direct wavefront measurements do exits, they carry additional complications and are only applicable in certain samples.\cite{wang2014rapid,wang2015direct} Therefore indirect wavefront sensing is generally preferred which requires inferring the aberrations present from the variance of a measure of the image quality.\cite{rodriguez2018adaptive} This adds an additional complication since there is no universal image quality metric. Indeed, they often vary between sample type and imaging modality.\cite{burke2015adaptive,booth2002adaptive,fienup2003aberration,debarre2008adaptive} For these reasons, a robust, easy-to-use implementation which incorporates multiple AO methods for multiple sample types/imaging modalities has yet to be presented.\cite{ji2017adaptive}

Microscope-AOtools provides such an implementation, utilising Python Microscope to provide control over the physical hardware. It incorporates methods for calibrating a DM, evaluating the success of the calibration in recreating aberrations and performing both direct wavefront sensing and sensorless adaptive optics corrections. The methods for sensorless adaptive optics correction can utilise a number from a suite of image quality metrics which can be easily extended to include additional sample or imaging method-specific metrics. These methods are automated, require minimal user involvement and setup and are tied to simple, descriptive  buttons on the Cockpit UI allowing for greater accessibility to users, shown in Figure~\ref{fig:DeepSIM_control_software}. The functions specific to the DM are shown in Figure~\ref{fig:DM_methods_cockpit}. These methods are divided into two categories; Set-up methods and Use-case methods. Figures~\ref{fig:DM_methods_cockpit_options} -~\ref{fig:DM_sensorless_ao_parameters} are optional windows that can be used by advanced users to change certain parameters used in the correction routines. How these parameters affect these routines will be explained in the relevant sections.

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.25\textwidth}
		\centering
		\includegraphics[width=\linewidth]{images/DM_methods_cockpit.jpg}
		\caption{}
		\label{fig:DM_methods_cockpit}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\centering
		\includegraphics[width=\linewidth]{images/DM_methods_cockpit_options.png}
		\caption{}
		\label{fig:DM_methods_cockpit_options}
	\end{subfigure}

	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\linewidth]{images/direct_wavefront_sensing_options.jpg}
		\caption{}
		\label{fig:DM_direct_wavefront_sensing_options}
	\end{subfigure}
	\begin{subfigure}{0.35\textwidth}
		\centering
		\includegraphics[width=\linewidth]{images/sensorless_ao_parameters.jpg}
		\caption{}
		\label{fig:DM_sensorless_ao_parameters}
	\end{subfigure}
	\caption{(a) Deformable mirror specific functions on the Cockpit UI (b) Options window used for changing the image quality metric used in the sensorless AO routine and to spawn additional parameter varying windows. Spawned by right-clicking on the AO methods (c) Options window for varying the parameters used in the system aberration routing correciton routing. Spawned by the "Set System Flat Calculation Parameters" button (d) Options window for varying the parameters used in the sensorless AO routine. Spawned by the "Set Sensorless Parameters" button}
	\label{fig:DeepSIM_control_software}
\end{figure}

\subsection{Set-up Methods}
\label{subsec:set_up_methods}

As previously described, DeepSIM has multiple beam paths; interferometric, widefield and SIM. The interferometric beampath is used for calibrating the deformable mirror. The interferometric image is formed by the interference between the reference beam arm and the system beam arm. However due to differences in magnification, the size of the reference beam is larger than that of the system beam. Therefore it is necessary to have a method for selecting the interferometric region of interest (ROI) i.e. the region where the reference and system beam arms interfere. Cockpit implements such a method as the functionality of the "Select ROI" button shown in Figure~\ref{fig:DM_methods_cockpit}. This spawns the windown shown in Figure~\ref{fig:ROI_selectors} where the user can draw a circle which will define the inferferometric ROI. This coordinates of this ROI are saved to the microscope's configuration files with the "Save ROI" button.

\begin{figure}[h]
	\centering
	\begin{subfigure}{0.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{images/ROI_selector_init.jpg}
		\caption{}
		\label{fig:ROI_selector_init}
	\end{subfigure}
	\begin{subfigure}{0.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{images/ROI_selector.jpg}
		\caption{}
		\label{fig:ROI_selector}
	\end{subfigure}
	\caption{User interface for selecting the interferometric region of interest (a) The ROI selecter UI when it is first initialised (b) UI with the ROI selected}
	\label{fig:ROI_selectors}
\end{figure}

\subsubsection{Direct wavefront sensing}
\label{subsubsec:direct_wavefront_sensing}

The two most common methods for direct wavefront sensing are Shack-Hartmann and interferometric methods. Shack-Hartmann wavefront sensing is useful for instances where accuracy is less important than the speed of wavefront recovery. While these situations do exist, the current use-cases for direct wavefront sensing within DeepSIM and Microscope-AOtools are calibration and system aberration correction. These are both situation where accuracy is considerably more important than speed. Additionally, implementing phase extraction from interferometric data has proved more challenging  to implement in an automatic fashion. Interferometric data can be defined as:

\begin{equation}\label{eq:I_basic}
I(x,y,t) = a(x,y) + b(x,y)cos[\phi(x,y) + \Phi_{R}(x,y,t)]
\end{equation}

Where $a(x,y)$ describes the variation of the background illumination, $b(x,y)$ describes the noise and contrast variations, $\phi(x,y)$ describes the phase imparted by the DM surface and $\Phi_{R}(x,y,t)$ is the reference phase at time $t$. $\Phi_{R}(x,y,t)$ can be arbitrarily set to 0. Doing this and then expanding the cosine term using Euler's formula, as well as the definition that $c(x,y) = \frac{1}{2}b(x,y)e^{i\phi(x,y)}$ leads to:

\begin{equation}\label{eq:I_cos_expand}
I(x,y) = a(x,y) + c(x,y) + c^{*}(x,y)
\end{equation}

Applying the 2-D Fourier transform Equation~\ref{eq:I_cos_expand} becomes:

\begin{equation}\label{eq:I_fourier}
\boldsymbol{I}(u,v) = \boldsymbol{A}(u,v) + \boldsymbol{C}(u,v) + \boldsymbol{C}^{*}(u,v)
\end{equation}

Now, given that $I(x,y)$ is real valued, it naturally follows that $\boldsymbol{I}(u,v)$ is Hermitian. The amplitude spectrum is symmetric around the zero position (i.e. $u = 0$, $v = 0$). This means that $\boldsymbol{C}(u,v)$ and $\boldsymbol{C}^{*}(u,v)$ must contain the same information, only centred on different spatial frequencies. One can apply a bandpass filter in the spatial frequency domain to remove both $\boldsymbol{A}(u,v)$ and $\boldsymbol{C}^{*}(u,v)$ to leave only $\boldsymbol{C}(u,v)$.\cite{lewis1993absolute} Applying the inverse Fourier transform yields $c(x,y)$, which is now complex. The phase of the wavefront can then be recovered by:

\begin{equation}\label{eq:phase}
\phi(x,y) = \arctan \frac{\Im\{c(x,y)\}}{\Re\{c(x,y)\}}
\end{equation}

In the phase unwrapping workflow shown in Figure~\ref{fig:phase_unwrap_workflow}, these mathematical steps are implemented in a practical way. The interferogram (\ref{fig:puw_inteferogram}) is cropped (\ref{fig:puw_inteferogram_cropped}) and the ROI, that is the area described by Equation~\ref{eq:I_basic}, is isolated by masking out all the information outside the ROI. This is provided by the user using the ROI selector shown in Figure~\ref{fig:ROI_selector}. Quadrant shifting the image (\ref{fig:puw_data_fftshift}) and applying a tukey window mask (\ref{fig:puw_tukey_window}) is done to minimise the spurious spatial frequencies which arise from performing a fast Fourier transform (FFT) on an image with sharp discontinuities at the quadrant edges.

\begin{figure*}
	\centering
	\begin{subfigure}{0.23\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/puw_inteferogram.png}
		\caption{}
		\label{fig:puw_inteferogram}
	\end{subfigure}
	\begin{subfigure}{0.23\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/puw_inteferogram_cropped.png}
		\caption{}
		\label{fig:puw_inteferogram_cropped}
	\end{subfigure}
	\begin{subfigure}{0.23\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/puw_mask.png}
		\caption{}
		\label{fig:puw_mask}
	\end{subfigure}
	\begin{subfigure}{0.23\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/puw_data_masked.png}
		\caption{}
		\label{fig:puw_data_masked}
	\end{subfigure}
	
	\begin{subfigure}{0.23\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/puw_data_fftshift.png}
		\caption{}
		\label{fig:puw_data_fftshift}
	\end{subfigure}
	\begin{subfigure}{0.23\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/puw_tukey_window.png}
		\caption{}
		\label{fig:puw_tukey_window}
	\end{subfigure}
	\begin{subfigure}{0.23\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/puw_fringes_tukey.png}
		\caption{}
		\label{fig:puw_fringes_tukey}
	\end{subfigure}
	\begin{subfigure}{0.23\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/puw_new_fringe_fft.png}
		\caption{}
		\label{fig:puw_new_fringe_fft}
	\end{subfigure}
	
	\begin{subfigure}{0.23\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/puw_new_fringe_fft_centre_blocked.png}
		\caption{}
		\label{fig:puw_new_fringe_fft_centre_blocked}
	\end{subfigure}
	\begin{subfigure}{0.23\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/puw_fft_filter.png}
		\caption{}
		\label{fig:puw_fft_filter}
	\end{subfigure}
	\begin{subfigure}{0.23\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/puw_new_fringe_order1.png}
		\caption{}
		\label{fig:puw_new_fringe_order1}
	\end{subfigure}
	\begin{subfigure}{0.23\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/puw_order1_roll.png}
		\caption{}
		\label{fig:puw_order1_roll}
	\end{subfigure}
	
	\begin{subfigure}{0.23\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/puw_complex_phase.png}
		\caption{}
		\label{fig:puw_complex_phase}
	\end{subfigure}
	\begin{subfigure}{0.23\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/puw_phaseorder1.png}
		\caption{}
		\label{fig:puw_phaseorder1}
	\end{subfigure}
	\begin{subfigure}{0.23\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/puw_phaseorder1mask}
		\caption{}
		\label{fig:puw_phaseorder1mask}
	\end{subfigure}
	\begin{subfigure}{0.23\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/puw_unwrapped_phase.png}
		\caption{}
		\label{fig:puw_unwrapped_phase}
	\end{subfigure}
	\caption{A visualisation of the stages of the phase unwrap workflow. (a) Captured interferogram (b) Interferogram cropped to region of interest (ROI) (c) Circular mask (d) ROI isolated (e) ROI quadrant shifted (ROI-qs) (f) 2-D tukey window mask (g) ROI-qs with tukey mask applied (h) Fast Fourier transform (FFT) of (g), log scaled (i) Fourier transform with the central spatial frequencies masked, log scaled (j) 2-D sine squared mask centred on the position of spatial frequencies encoding the phase information (k) The original Fourier transform, (h), with the sine squared mask applied (l) Phase encoding spatial frequencies rolled to the central position (m) Inverse FFT of the phase encoding spatial frequencies (n) Inverse FFT transformed into a phase map (o) Phase map masked to isolate ROI (p) Phase map unwrapped to remove 2$\pi$ discontinuities}
	\label{fig:phase_unwrap_workflow}
\end{figure*}

Having performed the FFT (\ref{fig:puw_new_fringe_fft}), an array described by Equation~\ref{eq:I_fourier} is obtained. A selection of the central spatial frequencies are masked (\ref{fig:puw_new_fringe_fft_centre_blocked}), primarily to mask out the central spatial frequency which represents the mean intensity and has an amplitude orders of magnitude larger than any other spatial frequency. The spatial frequencies which now have the highest amplitudes correspond to both $\boldsymbol{C}(u,v)$ and $\boldsymbol{C}^{*}(u,v)$. One of the aforementioned amplitude peaks is located and a bandpass filter described by $\sin^{2}(x,y)$ is constructed (\ref{fig:puw_fft_filter}) centred on the spatial frequency location of this amplitude peak. As previously noted, the Fourier transform of the interferogram is symmetrical around the central spatial frequency. So, it doesn't matter which of the two peaks this filter is centred on since they encode the same information. This bandpass filter is then applied to the FFT of the interferogram (\ref{fig:puw_new_fringe_order1}) and these spatial frequencies are then rolled to the central spatial frequency position (\ref{fig:puw_order1_roll}). This successfully filters $\boldsymbol{A}(u,v)$ and $\boldsymbol{C}^{*}(u,v)$, isolating $\boldsymbol{C}(u,v)$ as desired.

The array corresponding to $\boldsymbol{C}(u,v)$ is inverse Fourier transformed to yield $c(x,y)$ (\ref{fig:puw_complex_phase}). This is then converted to a phase map by performing the calculation in Equation~\ref{eq:phase} (\ref{fig:puw_phaseorder1}) and the mask in Figure~\ref{fig:puw_mask} is applied again to mask out any spurious noise outside the ROI. Due to the periodic nature of trigonometric functions, this phase map is wrapped around $-\pi$ and $\pi$. An 2D  algorithm is used to unwrap the phase map and yield a phase map similar to Figure~\ref{fig:puw_unwrapped_phase} is obtained.\cite{herraez2002fast} Other than determining the appropriate ROI, this workflow is entirely automated and requires no user input. 

This automation does have a drawback. The location of the phase component of the Fourier transform is determined by finding the maximum intensity in the data represented by Figure~\ref{fig:puw_new_fringe_fft_centre_blocked} and then performing a number of centre of mass calculations to find the `true' centre of the phase component. However, this `true' centre may still be incorrect by a few pixels. This leads to an artificial introduction of tip and/or tilt in the final wavefront and this artificial tip/tilt cannot be separated from the true tip/tilt. Therefore, this phase unwrapping implementation cannot be said to be sensitive to tip or tilt. However, since tip and tilt (along with piston) are not considered to be a true optical aberration, this is a small price to pay for a fully automated phase unwrapping workflow.

This phase unwrapping method is used as part of other methods, but it is also useful for a user to be able to visualise the phase. Principly this is because if the interferogram is not well focused on the camera it can result in the wavefront being heavily distorted by the Zernike mode corresponding to the defocus optical aberration (Noll Index 4). This can mask smaller wavefront deformations caused by the movement of the DM actuators and therefore bias calibration measurements. It is can also be useful to view the system aberrations present, to check the difference applying the system aberration correction makes to the wavefront shape and to manually check for discontinuities. Cockpit implements such a method as the functionality of the "Visualise Phase" button shown in Figure~\ref{fig:DM_methods_cockpit}. This spawns the windown shown in Figure~\ref{fig:phase_viewer_phase}, displaying the phase wavefront acquired from the interferogram. The display can be changed to the power spectrum of the interferogram, Figure~\ref{fig:phase_viewer_ft}, and back by pressing the "Real/Fourier Transform switch" button. 

\begin{figure}[h]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/phase_viewer_phase.jpg}
		\caption{}
		\label{fig:phase_viewer_phase}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/phase_viewer_ft.jpg}
		\caption{}
		\label{fig:phase_viewer_ft}
	\end{subfigure}
	\caption{(a) Phase viewer window showing the unwrapped phase acquired from the interferogram (b) Phase viewer window showing the power spectrum of the interferogram. }
	\label{fig:phase_viewer}
\end{figure}

\subsubsection{Calibration}
\label{subsubsec:calibration}

For aberration correction, one could attempt to measure the overall aberration of the optical wavefront and apply the opposite shape to the DM. For direct wavefront sensing, this would appear as simple as measuring the phase distortion and shaping the DM to cancel this distortion. However, for continuous membrane DMs (which the majority of commercially available DMs are) the response of mirror shape to the actuators which control the mirror shape is generally non-linear, due to the membrane's mechanical elasticity, electrostatic forces and the coupling between actuators.\cite{Zhu:99} For indirect wavefront sensing this presents an even greater problem since any minimisation of the wavefront aberration would involve \textit{N} degrees of freedom, where \textit{N} is the number of actuators. Assuming that the overall mirror shape is the linear superposition of all the individual actuator deflections, we can define the overall mirror shape, $S(x,y)$ as:

\begin{equation}\label{eq:surface_shape}
\Delta S(x,y) = \sum_{l=1}^{N} d_{l}\phi_{l}(x,y)
\end{equation}

Where $\Delta S(x,y)$ is the change in the DM shape from its original position, $d_l$ is the $l$-th actuator control signal (an arbitrary value related to applied voltage which determines the position the $l$-th actuator in its overall movement range)	and $\phi_{l}(x,y)$ is the $l$-th influence function. We can change this orthogonal set of basis functions for a different sensible basis set. An obvious alternative basis set is the Zernike polynomials since the wavefront distortion can be approximated by the linear addition of Zernike polynomials.\cite{von1934beugungstheorie,noll1976zernike} Describing $\phi_{l}(x,y)$ in terms of Zernike polynomials we obtain:

\begin{equation}\label{eq:influence_to_zernike}
\phi_{l}(x,y) = \sum_{k=1}^{M} b_{k,l}z_{k}(x,y)
\end{equation}

Where $b_{k,l}$ is the coefficient corresponding to the $k$-th Zernike polynomial due to the $d_l$. This leads to:

\begin{equation}\label{eq:zernike_sub}
\begin{split}
\Delta S(x,y) & = \sum_{l=1}^{N} d_{l}\left[\sum_{k=1}^{M} b_{k,l}z_{k}(x,y)\right] \\
& =\sum_{k=1}^{M} \left(\sum_{l=1}^{N} d_{l} b_{k,l}\right) z_{k}(x,y) \\
& =\sum_{k=1}^{M} a_{k} z_{k}(x,y)
\end{split}
\end{equation}

Where the new Zernike coefficients, $a_{k}$, is defined as:

\begin{equation}\label{eq:new_z_coef}
a_{k} = \sum_{l=1}^{N} b_{k,l} d_{l} \text{~for~} k=1,2,...,M
\end{equation}

Converting this to a matrix form yields:

\begin{equation}\label{eq:CM_derivation}
\begin{split}
\bar{a} &= \boldsymbol{B} \bar{d}\\
\Rightarrow \bar{d} &= \boldsymbol{C} \bar{a}
\end{split}
\end{equation}

Where $\bar{d}$ is a length $N$ vector of the actuator control signals, $\bar{a}$ is the length $M$ vector of the Zernike polynomial amplitudes and $\boldsymbol{B}$ is the $M \times N$ matrix representing the response characteristics of the DM. However, we actually want its inverse, $\boldsymbol{B}^{-1} =\boldsymbol{C}$, otherwise called the control matrix in order to convert from Zernike polynomial amplitudes to actuator control signals.

Microscope-AOtools implements an automated calibration routine to obtain $\boldsymbol{C}$. Each actuator is moved through a number, $p$, of set positions and a wavefront is extracted. Then $M$ Zernike modes, modelled with a Python package, are then fitted to the wavefront.\cite{townson2019aotools} A row vector $\boldsymbol{z}$ is obtained:

\begin{equation}\label{eq:zernike_amp}
\boldsymbol{z} = 
\begin{bmatrix}
z_{1} & z_{2} & \cdots & z_{m} 
\end{bmatrix}
\end{equation}

Where the $k$-th element is the amplitude of the $k$-th Zernike mode. By collecting the row vectors of each position for each $l$-th actuator we can obtain:

\begin{equation}\label{eq:zernike_amp_actuator}
A_l = 
\begin{bmatrix}
\boldsymbol{z_{1}}\\
\boldsymbol{z_{2}}\\
\vdots\\
\boldsymbol{z_{p}} 
\end{bmatrix}
=
\begin{bmatrix}
z_{1,1} & z_{1,2} & \cdots & z_{1,m} \\
z_{2,1} & z_{2,2} & \cdots & z_{2,m} \\
\vdots  & \vdots  & \ddots & \vdots  \\
z_{p,1} & z_{p,2} & \cdots & z_{p,m} 
\end{bmatrix}
\end{equation}

Fitting linear regression to each column, $\begin{bmatrix} z_{1,i} & z_{2,i} & \cdots & z_{p,i} \end{bmatrix}^T$, yields the response characteristics between the $l$-th actuator's position and the $k$-th Zernike mode, $b_{k,l}$. In this way, we construct $\boldsymbol{B}$ and then calculate $\boldsymbol{C}$. Figure~\ref{fig:calibration_workflow} shows a flowchart representing this process as implemented in Microscope-AOtools.

\begin{figure}[h]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/calibration_routine_workflow.jpg}
		\caption{}
		\label{fig:calibration_routine_workflow}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{images/Ith_actuator_calibration_workflow_blue_border.jpg}
		\caption{}
		\label{fig:Ith_actuator_calibration_workflow_blue_border}
	\end{subfigure}
	\caption{(a) Flowchart depicting the generalised calibration routine implemented in Mircoscope-AOtools (b)Flowchart depicting the the process for calibrating the $l$-th actuator of the deformable mirror, the dashed blue process in (a). The influence functions returned are $b_{k,l}$ described in Equation~\ref{eq:influence_to_zernike}. This process is performed for each $N$ actuators and used to obtain $\boldsymbol{C}$ described in Equation~\ref{eq:CM_derivation}.}
	\label{fig:calibration_workflow}
\end{figure}

In general, $\boldsymbol{B}$ is singular and therefore has no true inverse and so we must use a pseudo-inverse, calculated using single value decomposition (SVD). However, some values of $\boldsymbol{B}$ may be small since the physical position of certain actuators will mean they have limited influence on creating certain Zernike modes. A control matrix calculated without thresholding out these small values will quickly lead to a saturation of the DM actuators (i.e. all actuators at their maximum stroke length) when corrections are calculated.\cite{booth2005methods} Therefore the calibration method incorporates a threshold by default and the exact threshold can be varied by experienced users. The calibration routine is initiated by pressing the "Calibrate" button shown in Figure~\ref{fig:DM_methods_cockpit}.

\subsubsection{Characterisation}
\label{subsubsec:characterisation}

A potential problem with the automated calibration routine is a lack of feedback. This issue arises from a number of places including the fact that some parameters, such as the number of steps used to calibrate each actuator and the threshold used in the SVD pseudo-inversion, are chosen somewhat arbitrarily, the approximate nature of the pseudo-inverse, and discretisation errors in the measuring of Zernike modes. It is therefore necessary to have some measure of how well the deformable mirror is able to recreate desired Zernike modes. This process is called characterisation. The process involves applying a fixed amplitude of a single Zernike mode to the mirror, measuring the Zernike mode applied and comparing the amplitude to that supposedly applied. An automated implementation of this process is present in Microscope-AOtools with the results returned to the user for interrogation. Figure~\ref{fig:characterisation_workflow} shows a flowchart of this method in Microscope-AOtools. The background wavefront distortion is measured and the Zernike mode amplitudes are measured. These are subtracted from the Zernike modes measured with deformations applied to the mirror to give an accurate assessment of the shape of the deformable mirror. 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.4\textwidth, scale=0.5]{./images/characterisation_workflow.jpg}
	\caption{Flowchart depicting the process for characterising a deformable mirror as implemented in Microscope-AOtools}
	\label{fig:characterisation_workflow}
\end{figure}

In an ideal situation, where the control matrix provided a perfect linear map from Zernike mode amplitudes to DM actuator positions, we would expect to see a characterisation assay like that in Figure~\ref{fig:characterisation_assay_ideal}, where only the desired Zernike mode is applied. In practice, the mirror is better at recreating particular Zernike modes than others and the coupled nature of the actuators means that small amplitudes of other Zernike modes are also present. The drop in quality of recreation becomes pronounced at high order Zernike modes since a deformable mirror (in this case, an Alpao-69 deformable mirror) lacks the adequate degrees of freedom to accurately recreate complex Zernike modes.

\begin{figure}[h]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=0.8\linewidth, scale=0.5]{./images/characterisation_assay_ideal.png}
		\caption{}
		\label{fig:characterisation_assay_ideal}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=1\linewidth, scale=0.5]{./images/characterisation_assay_real.png}
		\caption{}
		\label{fig:characterisation_assay_real}
	\end{subfigure}
	\begin{subfigure}{0.9\textwidth}
		\centering
		\includegraphics[width=0.5\linewidth, scale=0.5]{./images/characterisation_assay_real_diag_and_avg.png}
		\caption{}
		\label{fig:characterisation_assay_ideal_diag_and_avg}
	\end{subfigure}
	\caption{(a) An ideal characterisation assay, measuring the recreation accuracy of 68 Zernike modes with applied amplitude of 1 for each (b) A realistic characterisation assay obtained from a calibrated Alpao-69 actuator DM, measuring the recreation accuracy of 68 Zernike modes with applied amplitude of 1 for each (c) Plot of the amplitudes desired Zernike modes i.e. the diagonal values of the characterisation assay. Individual values plotted as well as a shifting average (the average of the current mode and all preceding modes)}
	\label{fig:characterisation_assay_results}
\end{figure}

Whether a calibration routine is considered a 'success' depends on the requirements of the DM within the system. Taking the characterisation assay shown in Figure~\ref{fig:characterisation_assay_real}, if success criteria for the DM is to be able correct for the first 20 Zernike modes with an 80\% accuracy, the calibration routine could be considered successful based on the characterisation assay generated. However, if the success criteria were for 90\% recreation accuracy for the first 30 Zernike modes, then the calibration routine would not have been successful and would need to be performed again, likely with altered parameters. It is left to the user to determine the success criteria for the DM calibration but Microscope-AOtools provides the tool necessary to determine whether they have been satisfied or not. The charaterisation routine is initiated by pressing the "Characterise" button shown in Figure~\ref{fig:DM_methods_cockpit}. Once the characterisation routine is complete, the characterisation assay and plot of the Zernike mode amplitudes on the diagonal, Figures~\ref{fig:characterisation_assay_real} and \ref{fig:characterisation_assay_ideal_diag_and_avg}, are displayed in a window for the user.

\subsubsection{System Aberration Correction}
\label{subsubsec:system_correction}

The applications for aberration correction using direct wavefront sensing have been well documented. However, the wavefront is measured (interferometry, Shack-Hartmann wavefront sensor, fluorescent guide star, etc) being able to measure the Zernike modes present and correct for them is a useful method to have for correcting both system and sample induced aberrations. Microscope-AOtools implements a correction method where the wavefront if observed directly. This is not a complex method. The workflow is shown in Figure~\ref{fig:direct_wavefront_flattening_workflow}. The wavefront is obtained through whatever direct wavefront sensing method has been implemented and selected, a number of Zernike modes determined by the user are fitted to the wavefront, an equal and opposite magnitude of these modes are applied to the DM. The RMS wavefront error is then obtained. This process repeats until $N$ iterations have been performed and the RMS wavefront error is below a user defined error threshold, $\delta$.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.55\textwidth, scale=0.5]{./images/direct_wavefront_flattening_workflow.png}
	\caption{Flowchart depicting the process for flattening directly measured wavefront as implemented in Microscope-AOtools}
	\label{fig:direct_wavefront_flattening_workflow}
\end{figure}

In an ideal setup with a perfect control matrix, this process would only need to be performed once. However, as we have already discussed, the control matrices generated for any setup are never `perfect'. Therefore, one iteration of this method would correct the aberrations to an extent, but it would leave residual aberrations. It is necessary to perform this process for a number of iterations to ensure the optimal wavefront is obtained. 

Figure~\ref{fig:direct_wavefront_correction} shows the results of one such wavefront correction. The wavefront was obtained by interferometry and, due to previously mentioned insensitivity to tip and tilt and since piston, tip and tilt are not true optical aberrations, Zernike modes 4-69 (using Noll indices) were corrected over 10 iterations. The RMS phase errors in Figures~\ref{fig:aberrated_wavefront_defocus_ptt_rmv_crop_phase_only} and \ref{fig:flattened_wavefront_10it} are 28.58368 radians and 3.11921 radians respectively. Figure~\ref{fig:zernike_modes_to_show_flattening} shows the Zernike mode amplitudes before and after correction. Clearly there is some over-correction in the defocus mode (Noll index 4) in particular which is visible in Figure~\ref{fig:flattened_wavefront_10it}. The dots visible are the physical location of the actuators on the DM and represent a limiting factor in how flat the DM surface can actually be. 

\begin{figure}[h]
	\centering
	\begin{subfigure}{0.33\textwidth}
		\includegraphics[scale=2]{./images/aberrated_wavefront_defocus_ptt_rmv_crop_phase_only.png}
		\caption{}
		\label{fig:aberrated_wavefront_defocus_ptt_rmv_crop_phase_only}
	\end{subfigure}
	\begin{subfigure}{0.425\textwidth}
		\includegraphics[scale=2]{./images/flattened_wavefront_10it_ptt_rmv_phase_colorbar1.png}
		\caption{}
		\label{fig:flattened_wavefront_10it}
	\end{subfigure}

	\begin{subfigure}{0.5\textwidth}
		\includegraphics[scale=2]{./images/zernike_amps_before_and_after_10it_modes_4to69.png}
		\caption{}
		\label{fig:zernike_modes_to_show_flattening}
	\end{subfigure}
	\caption{(a) An aberrated wavefront (b) A wavefront after 10 iterations of correction (c) The Zernike mode amplitudes measured in the aberrated (red) and corrected (blue) wavefronts (a) - (b) are all presented on the same colorscale (in radians) and were obtains via interferometry}
	\label{fig:direct_wavefront_correction}
\end{figure}

Similar to the calibration routine, the success criteria for direct wavefront correction is left to the user. For direct wavefront corrections preformed on samples, the preference may be to obtain the best possible correction within \textit{N} iterations. For system aberration corrections using an interferometer, where photo bleaching is not an issue, is may be preferable to simply set a minimum error and continue to iterate until this threshold is reached. Microscope-AOtools implements both options to ensure generalisability.

The charaterisation routine is initiated by pressing the "Calculate System Flat" button shown in Figure~\ref{fig:DM_methods_cockpit}. Spawning the window shown in Figure~\ref{fig:DM_direct_wavefront_sensing_options} allows a user to vary the number of iterations and RMS error threshold used for the waevefront correction routine. By default the routine runs for exactly 10 iterations, since the default error threashold is $\infty$ and so any wavefront deformation will yeild an RMS value under this threshold. A user can also vary the Zernike modes the wavefront flatting routine will try to correct for. By default these are all Zernike modes with Noll indices, $j$, $\ge$ 4 (i.e. all the true optical aberrations) and $<$ the number of actuators, N. Once the Characterisation routine has been performed this is changed to be all Zernikes modes with $4 \le j < N$ and with a recreation accuracy greater than 75\% (i.e. a value above 0.75 on the diagonal of the Chararacterisation assay for that mode). Once the actuator values for correcting the system aberrations have been calculated they are stored in Cockpit's internal configuration and can be applied at any time using the "System Flat" button shown in Figure~\ref{fig:DM_methods_cockpit}.

\subsection{Use Case Methods}
\label{subsec:use_case_methods}

\subsubsection{Sensorless Correction}
\label{subsubsec:sensorless_correction}

In many biological applications, direct wavefront sensing is not possible and so we rely on wavefront sensorless techniques to determine the best correction to apply. The generalised methodology for this is shown in Figure~\ref{fig:sensorless_correction_method}. Some metric, $S$, which gives some useful measure of the image quality is chosen. For each Zernike modes, $Z_{i}$, a number of amplitudes of that mode, $a_{j}$, are applied and an image of the sample obtained for each. The image quality of each image, $S_{j}$ is obtained. Assuming that $S$ is a function of $a$, fitting a Gaussian function to the $S_{j}$ values yields an Zernike mode amplitude, $a_{max}$, which should, theoretically, yield the best image quality, $S_{max}$. 

\begin{figure}[h]
	\centering
	\includegraphics[width=1\textwidth,scale=0.5]{./images/sensorless_aberration_fitting_w_images.png}
	\caption{Principle of sensorless adaptive optics correction. For each Zernike mode, $Z_i$, images of the sample with different amplitudes of the $i$-th Zernike mode are obtained. A value of the image quality metric, $S$, is obtained for each (blue dots). A Gaussian function is then fitted to these values and the amplitude, $a$ corresponding to the maximum image quality, $S_{max}$, is obtained (green dot). The inset images are Drosophila Neuro-muscular Junction with various amplitudes of spherical aberration present.}
	\label{fig:sensorless_correction_method}
\end{figure}

The complexity of sensorless adaptive optics correction lies in selecting the best image quality metric. There have been numerous metrics developed which have been shown to be effective on certain sample types or imaging modalities.\cite{burke2015adaptive,booth2002adaptive,fienup2003aberration,debarre2008adaptive} In order for an adaptive optics implementation to be considered generalised, it should not be tied to a particular sample type or imaging modality. For this reason, Microscope-AOtools offers a range of image quality metrics, all located in the \textit{aoMetrics.py}, and which we will discuss shortly.  

Unlike the calibration, characterisation and direct wavefront sensing techniques, the sensorless adaptive optics routine is not a method implemented in Microscope-AOtools and simply called by Cockpit. Instead, the sensorless correction routine relies on coordination from Cockpit, Python Microscope and Microscope-AOtools. The biological sample is set up in the image plane. A known amplitude of the first Zernike mode to be corrected for is applied to the DM by Microscope-AOtools, Then the light sources and camera are triggered by Python Microscope and the image data is collected by cockpit. This is repeated for $M$ measurements. Then, Cockpit passes the $M$ images to Microscope-AOtools where the image quality metric for each image is evaluated. These values are then used to fit a Gaussian function and the mean of the Gaussian yields the Zernike mode amplitudes which should yield the maximum image quality, $a_{max}$. This amplitude is then applied to the DM and stored as the offset on top of which all further corrections should be applied. This process is then repeated for $N$ Zernike modes. This whole process is then repeated for $T$ iterations. Finally, the recorded Zernike mode amplitudes which have been corrected for and the actuator positions associated with that correction are stored in in Cockpit's internal configuration. The sensorless adaptive optics routine is initiated by pressing the "Sensorless AO" button shown in Figure~\ref{fig:DM_methods_cockpit}. The workflow of this routine is shown in Figure~\ref{fig:sensorless_correction_workflow_DeepSIM}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.65]{./images/sensorless_correction_workflow_DeepSIM.jpg}
	\caption{Flowchart depicting the sensorless correction routine implemented on DeepSIM. All $M$ images are taken, then the quality metric is obtained for all $M$ images, the best Zernike amplitude is found and applied }
	\label{fig:sensorless_correction_workflow_DeepSIM}
\end{figure}

Clearly, this sensorless routine has multiple parameters and there is a limited degree to which these can be automatically selected. To this end, Figures~\ref{fig:DM_methods_cockpit_options} \&~\ref{fig:DeepSIM_control_software} have allow a user to vary these parameters. Figure~\ref{fig:DM_methods_cockpit_options} shows various options the user can select for the image quality metric to be used. As previously mentioned, different image quality metrics are optimised for different imaging modalities and sample types. Allowing the user to easily switch between metrics is critical for a generalised implementation of adaptive optics which is accessible to users. Figure~\ref{fig:DeepSIM_control_software} shows a window which allows the user to vary the number of iterations, $T$, the Zernike modes to be corrected, $N$ and the number of measurements for each mode, $M$. By default, the Zernike modes corrected for are $1^{st}$ and $2^{nd}$ order spherical aberration, coma, astigmatism and trefoil as these are often the source of the most significant wavefront deformation, and therefore loss of image quality, in biological samples. The amplitudes applied to the DM are evenly spaced between the "Aberration range minima", $j_{min}$ and "Aberration range minima", $j_{max}$,in $M$ intervals. To ensure that the Gaussian fitting to find $a_{max}$ yields a reasonable value, the fitting has bounds defined as $(j_{max}-j_{min}) \pm 0.25(j_{max}-j_{min})$.